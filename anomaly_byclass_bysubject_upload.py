# -*- coding: utf-8 -*-
"""Anomaly_ByClass_BySubject_Upload.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O8kwWV5S51qN4Co3lX3UABZkJih2QQLZ

# üéì Ph√°t hi·ªán ƒëi·ªÉm b·∫•t th∆∞·ªùng ƒëi·ªÉm s·ªë h·ªçc sinh (L·ªõp & M√¥n)
"""

# === THAM S·ªê PH√ÇN T√çCH ===
Z_THRESH = 2.0
REQUIRE_COLUMNS = ["MaHS", "HoTen", "Lop"]   # c·ªôt chu·∫©n sau khi map alias

VALIDATE_SCORES = True
SCORE_MIN, SCORE_MAX = 0.0, 10.0

# === H√ÄM TI·ªÜN √çCH ===
import re
import unicodedata
import numpy as np
import pandas as pd

def strip_accents(s: str) -> str:
    if not isinstance(s, str):
        s = str(s)
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    return s

def norm_col(s: str) -> str:
    """chu·∫©n h√≥a t√™n c·ªôt: b·ªè d·∫•u, th∆∞·ªùng h√≥a, b·ªè kho·∫£ng tr·∫Øng/k√Ω t·ª± l·∫°"""
    s = strip_accents(s)
    s = s.lower().strip()
    s = re.sub(r"[^a-z0-9]+", "_", s)      # thay m·ªçi k√Ω t·ª± l·∫° b·∫±ng _
    s = re.sub(r"_+", "_", s).strip("_")
    return s

# C√°c alias hay g·∫∑p ‚Üí √°nh x·∫° v·ªÅ c·ªôt chu·∫©n
ALIAS_MAP = {
    # MaHS
    "mahs": "MaHS", "ma_hs": "MaHS", "studentid": "MaHS", "id": "MaHS", "mssv": "MaHS",

    # HoTen
    "hoten": "HoTen", "ho_ten": "HoTen", "ho_va_ten": "HoTen", "tenhs": "HoTen",
    "ten_hs": "HoTen", "studentname": "HoTen", "name": "HoTen",

    # Lop
    "lop": "Lop", "lop_hoc": "Lop", "class": "Lop", "class_name": "Lop", "ten_lop": "Lop"
}

def normalize_headers(df: pd.DataFrame) -> pd.DataFrame:
    """ƒê·ªïi t√™n c·ªôt theo ALIAS_MAP ‚Üí v·ªÅ c·ªôt chu·∫©n 'MaHS','HoTen','Lop' """
    mapping = {}
    for c in df.columns:
        key = norm_col(c)
        if key in ALIAS_MAP:
            mapping[c] = ALIAS_MAP[key]
    df = df.rename(columns=mapping)
    return df

def detect_score_columns(df: pd.DataFrame):
    """c·ªôt ƒëi·ªÉm = numeric, kh√°c 3 c·ªôt ƒë·ªãnh danh"""
    return [c for c in df.columns
            if c not in REQUIRE_COLUMNS and pd.api.types.is_numeric_dtype(df[c])]

def validate_scores(df: pd.DataFrame, score_cols):
    if not VALIDATE_SCORES:
        return df
    df = df.copy()
    for c in score_cols:
        df.loc[~df[c].between(SCORE_MIN, SCORE_MAX), c] = np.nan
    return df

def zscore_series(s: pd.Series) -> pd.Series:
    mu = s.mean(); sigma = s.std(ddof=0)
    if sigma == 0 or np.isnan(sigma):
        sigma = 1e-9
    return (s - mu) / sigma

def compute_anomalies(df: pd.DataFrame, z_thresh: float = 2.0):
    # 1) Chu·∫©n h√≥a header
    df = normalize_headers(df)

    # 2) B·∫Øt bu·ªôc c√≥ 3 c·ªôt chu·∫©n; n·∫øu thi·∫øu 'HoTen' th√¨ t·∫°o t·∫°m (kh√¥ng ch·∫∑n)
    missing = list(set(REQUIRE_COLUMNS) - set(df.columns))
    if "HoTen" in missing and "MaHS" in df.columns:
        df["HoTen"] = df["MaHS"].astype(str)    # ƒëi·ªÅn t·∫°m = MaHS
        missing.remove("HoTen")
    if missing:  # c√≤n thi·∫øu g√¨ kh√°c (v√≠ d·ª• 'Lop' ho·∫∑c 'MaHS') th√¨ d·ª´ng
        raise ValueError(f"Thi·∫øu c·ªôt b·∫Øt bu·ªôc: {missing}")

    # 3) ƒê·∫£m b·∫£o c·ªôt ƒëi·ªÉm l√† s·ªë
    for c in df.columns:
        if c not in REQUIRE_COLUMNS:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # 4) X√°c ƒë·ªãnh c·ªôt ƒëi·ªÉm
    score_cols = detect_score_columns(df)
    if not score_cols:
        raise ValueError("Kh√¥ng t√¨m th·∫•y c·ªôt ƒëi·ªÉm s·ªë n√†o (c√°c c·ªôt ngo√†i ƒë·ªãnh danh kh√¥ng ph·∫£i s·ªë).")

    # 5) T√≠nh to√°n
    df = validate_scores(df, score_cols).copy()
    df["DiemTB"] = df[score_cols].mean(axis=1, skipna=True)
    df["Z_tb"] = zscore_series(df["DiemTB"])
    df["BT_TB"] = df["Z_tb"].abs() > z_thresh

    for c in score_cols:
        df[f"Z_{c}"] = zscore_series(df[c])
        df[f"BT_{c}"] = df[f"Z_{c}"].abs() > z_thresh

    by_class_tb = (df.groupby("Lop")
                     .agg(TongHS=("MaHS", "count"),
                          BatThuong=("BT_TB","sum"))
                     .reset_index())
    by_class_tb["TyLe_%"] = (by_class_tb["BatThuong"]/by_class_tb["TongHS"]*100).round(2)

    rows = []
    for c in score_cols:
        rows.append({"Mon": c,
                     "BatThuong": int(df[f"BT_{c}"].sum()),
                     "TongHS": int(df["MaHS"].count())})
    by_subject = pd.DataFrame(rows)
    by_subject["TyLe_%"] = (by_subject["BatThuong"]/by_subject["TongHS"]*100).round(2)

    return {
        "out_full": df,
        "by_class_tb": by_class_tb.sort_values("BatThuong", ascending=False),
        "by_subject": by_subject.sort_values("BatThuong", ascending=False),
        "score_cols": score_cols
    }

import io, os
import matplotlib.pyplot as plt

if use_colab:
    print("üëâ Ch·ªçn 1 ho·∫∑c nhi·ªÅu file CSV ƒë·ªÉ upload")
    uploaded = files.upload()  # c√≥ th·ªÉ ch·ªçn nhi·ªÅu file
else:
    print("Kh√¥ng ·ªü Colab. G√°n 'uploaded' = {t√™n: bytes} n·∫øu test local.")
    uploaded = {}

if uploaded:
    for fname, raw in uploaded.items():
        print("="*80)
        print("Ph√¢n t√≠ch:", fname)

        # Th·ª≠ ƒë·ªçc nhi·ªÅu encoding n·∫øu c·∫ßn
        df = None
        for enc in ["utf-8-sig", "utf-8", "cp1258", "latin-1"]:
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc)
                break
            except Exception:
                df = None
        if df is None:
            print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c CSV v·ªõi c√°c encoding ph·ªï bi·∫øn.")
            continue

        try:
            res = compute_anomalies(df, z_thresh=Z_THRESH)
        except Exception as e:
            print("‚ùå L·ªói t√≠nh to√°n:", e)
            continue

        out_full = res["out_full"]
        by_class_tb = res["by_class_tb"]
        by_subject = res["by_subject"]

        base = os.path.splitext(os.path.basename(fname))[0]
        out_full.to_csv(f"{base}__ket_qua_chi_tiet.csv", index=False, encoding="utf-8")
        by_class_tb.to_csv(f"{base}__tong_hop_theo_lop.csv", index=False, encoding="utf-8")
        by_subject.to_csv(f"{base}__tong_hop_theo_mon.csv", index=False, encoding="utf-8")

        display(by_class_tb)
        display(by_subject)

        # Bi·ªÉu ƒë·ªì
        plt.figure(); plt.title(f"S·ªë HS b·∫•t th∆∞·ªùng theo L·ªöP (|Z_tb|>{Z_THRESH}) ‚Äì {fname}")
        plt.xlabel("L·ªõp"); plt.ylabel("S·ªë HS b·∫•t th∆∞·ªùng")
        plt.bar(by_class_tb["Lop"].astype(str), by_class_tb["BatThuong"])
        plt.xticks(rotation=45, ha="right"); plt.tight_layout(); plt.show()

        plt.figure(); plt.title(f"T·ª∑ l·ªá % b·∫•t th∆∞·ªùng theo L·ªöP ‚Äì {fname}")
        plt.xlabel("L·ªõp"); plt.ylabel("T·ª∑ l·ªá (%)")
        plt.bar(by_class_tb["Lop"].astype(str), by_class_tb["TyLe_%"])
        plt.xticks(rotation=45, ha="right"); plt.tight_layout(); plt.show()

        plt.figure(); plt.title(f"S·ªë HS b·∫•t th∆∞·ªùng theo M√îN (|Z_m√¥n|>{Z_THRESH}) ‚Äì {fname}")
        plt.xlabel("M√¥n"); plt.ylabel("S·ªë HS b·∫•t th∆∞·ªùng")
        plt.bar(by_subject["Mon"].astype(str), by_subject["BatThuong"])
        plt.xticks(rotation=45, ha="right"); plt.tight_layout(); plt.show()

        mu = out_full["DiemTB"].mean(); sigma = out_full["DiemTB"].std(ddof=0)
        left = mu - Z_THRESH*(sigma if sigma!=0 else 1e-9)
        right = mu + Z_THRESH*(sigma if sigma!=0 else 1e-9)
        plt.figure(); plt.title(f"Ph√¢n ph·ªëi DiemTB + ng∆∞·ª°ng Z (Œº={mu:.2f}, œÉ={sigma:.2f}) ‚Äì {fname}")
        plt.xlabel("DiemTB"); plt.ylabel("T·∫ßn su·∫•t")
        plt.hist(out_full["DiemTB"].dropna(), bins=20)
        plt.axvline(left, linestyle="--"); plt.axvline(right, linestyle="--")
        plt.tight_layout(); plt.show()
else:
    print("Ch∆∞a upload file.")